# install_github("atredennick/ecoforecastR") # get latest version
library(ecoforecastR) # MCMC manipulation (by M. Dietze)
####
####  LOAD DATA ----------------------------------------------------------------
####
snow_ynp  <- read.csv("../data/west_yellowstone_snotel_summary.csv", row.names = 1)
bison_raw <- read.csv("../data/YNP_bison_population_size.csv")
bison_dat <- bison_raw %>%
dplyr::select(-source) %>%     # drop the source column
mutate(set = ifelse(year < 2011, "training", "validation")) %>% # make new column for data splits
left_join(snow_ynp, by="year") # merge in SNOTEL data
####
####  JAGS State-Space Model ---------------------------------------------------
####
r_mu_prior <- log(1.11) # lambda = 1.11 in Hobbs et al. 2015
r_sd_prior <- sd(log(rnorm(100000,1.11,0.024))) # sd_lambda = 0.024 in Hobbs et al. 2015
my_model <- "
model{
#### Variance Priors
sigma_proc ~ dgamma(0.01,0.01)
tau_proc <- 1/sigma_proc^2
#### Fixed Effects Priors
r  ~ dnorm(0.1, 1/0.02^2) # intrinsic growth rate, informed prior
b  ~ dnorm(0,0.0001)      # strength of density dependence (r/K)
b1 ~ dnorm(0,0.0001)      # effect of snow
#### Initial Conditions
z[1] ~ dnorm(Nobs[1], tau_obs[1]) # varies around observed abundance at t = 1
#### Process Model
for(t in 2:npreds){
mu[t] <- max( 1, log( z[t-1]*exp(r + b*z[t-1] + b1*x[t]) ) )
z[t] ~ dlnorm(mu[t], tau_proc)
}
#### Data Model
for(j in 2:n){
Nobs[j] ~ dnorm(z[j], tau_obs[j])
}
}"
####
####  Fit Bison Forecasting Model ----------------------------------------------
####
##  For years without observation error, set to max observed standard deviation
##  TODO: Impute in the model?
na_sds                       <- which(is.na(bison_dat$count.sd)==T)
bison_dat[na_sds,"count.sd"] <- max(bison_dat$count.sd, na.rm=T)
##  Split into training and validation sets
training_dat   <- filter(bison_dat, set == "training")
validation_dat <- filter(bison_dat, set == "validation")
##  Set up SWE knowns (2011-2017), relative to scaling of observations
swe_mean     <- mean(training_dat$mean_snow_water_equiv_mm)
swe_sd       <- sd(training_dat$mean_snow_water_equiv_mm)
forecast_swe <- snow_ynp %>%
filter(year %in% validation_dat$year) %>%
pull(mean_snow_water_equiv_mm)
scl_fut_swe  <- (forecast_swe - swe_mean) / swe_sd
##  Set initial values for unkown parameters
inits <- list(
list(sigma_proc = 0.01,
r = 0.05,
b = 0.001,
b1 = -0.5),
list(sigma_proc = 0.3,
r = 0.4,
b = 0.1,
b1 = -0.01),
list(sigma_proc = 0.1,
r = 0.7,
b = 0.00001,
b1 = 0.2)
)
####
####  FIT AND FORECAST WITH KNOWN SWE
####
##  Prepare data list
mydat <- list(Nobs    = training_dat$count.mean, # mean counts
n       = nrow(training_dat), # number of observations
tau_obs = 1/training_dat$count.sd^2, # transform s.d. to precision
x       = c(as.numeric(scale(training_dat$mean_snow_water_equiv_mm)),scl_fut_swe), # snow depth, plus forecast years
npreds  = nrow(training_dat)+nrow(validation_dat)) # number of total predictions (obs + forecast)
##  Random variables to collect
out_variables <- c("r", "b", "b1", "sigma_proc", "z")
##  Send to JAGS
mc3     <- jags.model(file = textConnection(my_model),
data = mydat,
n.chains = length(inits),
n.adapt = 50000,
inits = inits)
################################################################################
##  bison_forecast.R: R script to fit a population growth model for YNP Bison,
##  forecast 10 new years, and partition the forecast variance.
##
##  Based on Dietze 2017, Ecological Applications
##  http://onlinelibrary.wiley.com/doi/10.1002/eap.1589/full
##
##  ____________________________________________________________________________
##  Author:       Andrew Tredennick (atredenn@gmail.com)
##  Date created: October 19, 2016
################################################################################
##  Clear everything...
rm(list = ls(all.names = TRUE))
##  Set working directory to source file location...
setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) # only for RStudio
####
####  LOAD LIBRARIES ----
####
library(tidyverse) # Data science functions
library(dplyr)     # Data wrangling
library(rjags)     # Fitting Bayesian models with JAGS
library(coda)      # MCMC summaries
# library(devtools) # For installing packages from GitHub
# install_github("atredennick/ecoforecastR") # get latest version
library(ecoforecastR) # MCMC manipulation (by M. Dietze)
####
####  LOAD DATA ----------------------------------------------------------------
####
snow_ynp  <- read.csv("../data/west_yellowstone_snotel_summary.csv", row.names = 1)
bison_raw <- read.csv("../data/YNP_bison_population_size.csv")
bison_dat <- bison_raw %>%
dplyr::select(-source) %>%     # drop the source column
mutate(set = ifelse(year < 2011, "training", "validation")) %>% # make new column for data splits
left_join(snow_ynp, by="year") # merge in SNOTEL data
####
####  JAGS State-Space Model ---------------------------------------------------
####
r_mu_prior <- log(1.11) # lambda = 1.11 in Hobbs et al. 2015
r_sd_prior <- sd(log(rnorm(100000,1.11,0.024))) # sd_lambda = 0.024 in Hobbs et al. 2015
my_model <- "
model{
#### Variance Priors
sigma_proc ~ dgamma(0.01,0.01)
tau_proc <- 1/sigma_proc^2
#### Fixed Effects Priors
r  ~ dnorm(0.1, 1/0.02^2) # intrinsic growth rate, informed prior
b  ~ dnorm(0,0.0001)      # strength of density dependence (r/K)
b1 ~ dnorm(0,0.0001)      # effect of snow
#### Initial Conditions
z[1] ~ dnorm(Nobs[1], tau_obs[1]) # varies around observed abundance at t = 1
#### Process Model
for(t in 2:npreds){
mu[t] <- max( 1, log( z[t-1]*exp(r + b*z[t-1] + b1*x[t]) ) )
z[t] ~ dlnorm(mu[t], tau_proc)
}
#### Data Model
for(j in 2:n){
Nobs[j] ~ dnorm(z[j], tau_obs[j])
}
}"
####
####  Fit Bison Forecasting Model ----------------------------------------------
####
##  For years without observation error, set to max observed standard deviation
##  TODO: Impute in the model?
na_sds                       <- which(is.na(bison_dat$count.sd)==T)
bison_dat[na_sds,"count.sd"] <- max(bison_dat$count.sd, na.rm=T)
##  Split into training and validation sets
training_dat   <- filter(bison_dat, set == "training")
validation_dat <- filter(bison_dat, set == "validation")
##  Set up SWE knowns (2011-2017), relative to scaling of observations
swe_mean     <- mean(training_dat$mean_snow_water_equiv_mm)
swe_sd       <- sd(training_dat$mean_snow_water_equiv_mm)
forecast_swe <- snow_ynp %>%
filter(year %in% validation_dat$year) %>%
pull(mean_snow_water_equiv_mm)
scl_fut_swe  <- (forecast_swe - swe_mean) / swe_sd
##  Set initial values for unkown parameters
inits <- list(
list(sigma_proc = 0.01,
r = 0.05,
b = -0.001,
b1 = -0.5),
list(sigma_proc = 0.3,
r = 0.4,
b = -0.1,
b1 = -0.01),
list(sigma_proc = 0.1,
r = 0.7,
b = -0.00001,
b1 = -0.2)
)
####
####  FIT AND FORECAST WITH KNOWN SWE
####
##  Prepare data list
mydat <- list(Nobs    = training_dat$count.mean, # mean counts
n       = nrow(training_dat), # number of observations
tau_obs = 1/training_dat$count.sd^2, # transform s.d. to precision
x       = c(as.numeric(scale(training_dat$mean_snow_water_equiv_mm)),scl_fut_swe), # snow depth, plus forecast years
npreds  = nrow(training_dat)+nrow(validation_dat)) # number of total predictions (obs + forecast)
##  Random variables to collect
out_variables <- c("r", "b", "b1", "sigma_proc", "z")
##  Send to JAGS
mc3     <- jags.model(file = textConnection(my_model),
data = mydat,
n.chains = length(inits),
n.adapt = 50000,
inits = inits)
####
####  FIT AND FORECAST ASSUMING AVG SWE
####
scl_fut_swe[] <- 0 # average is 0 by definition
##  Prepare data list
mydat <- list(Nobs    = training_dat$count.mean, # mean counts
n       = nrow(training_dat), # number of observations
tau_obs = 1/training_dat$count.sd^2, # transform s.d. to precision
x       = c(as.numeric(scale(training_dat$mean_snow_water_equiv_mm)),scl_fut_swe), # snow depth, plus forecast years
npreds  = nrow(training_dat)+nrow(validation_dat)) # number of total predictions (obs + forecast)
mydat
################################################################################
##  bison_forecast.R: R script to fit a population growth model for YNP Bison,
##  forecast 10 new years, and partition the forecast variance.
##
##  Based on Dietze 2017, Ecological Applications
##  http://onlinelibrary.wiley.com/doi/10.1002/eap.1589/full
##
##  ____________________________________________________________________________
##  Author:       Andrew Tredennick (atredenn@gmail.com)
##  Date created: October 19, 2016
################################################################################
##  Clear everything...
rm(list = ls(all.names = TRUE))
##  Set working directory to source file location...
root <- "~/Repos/bison_forecast/"
setwd(paste0(root,"code"))
getwd()
source('~/Repos/bison_forecast/code/analyze_posteriors.R')
source('~/Repos/bison_forecast/code/analyze_posteriors.R')
source('~/Repos/bison_forecast/code/analyze_posteriors.R')
source('~/Repos/bison_forecast/code/analyze_posteriors.R')
source('~/Repos/bison_forecast/code/analyze_posteriors.R')
####
####  MCMC DIAGNOSTICS ---------------------------------------------------------
####
# traceplot(swe_avg_posts)
# traceplot(swe_est_posts)
gelman.diag(swe_avg_posts)
####
####  MCMC DIAGNOSTICS ---------------------------------------------------------
####
# traceplot(swe_avg_posts)
# traceplot(swe_est_posts)
gelman.diag(swe_est_posts)
heidel.diag(swe_est_posts)
heidel.diag(swe_avg_posts)
source('~/Repos/bison_forecast/code/analyze_posteriors.R')
source('~/Repos/bison_forecast/code/analyze_posteriors.R')
source('~/Repos/bison_forecast/code/analyze_posteriors.R')
source('~/Repos/bison_forecast/code/fit_models.R')
################################################################################
##  analyze_posteriors.R: R script to plot the posterior distributions of model
##  parameters and to run MCMC diagnostics
##
##  ____________________________________________________________________________
##  Author:       Andrew Tredennick (atredenn@gmail.com)
##  Date created: October 19, 2016
################################################################################
##  Clear everything...
rm(list = ls(all.names = TRUE))
##  Set working directory to source file location
root <- "~/Repos/bison_forecast/"
setwd(paste0(root,"code/"))
####
####  LOAD LIBRARIES ----
####
library(tidyverse) # Data science functions
library(dplyr)     # Data wrangling
library(ggthemes)  # Pleasing themes for ggplot2
library(cowplot)   # Combining ggplots
library(rjags)     # Fitting Bayesian models with JAGS
library(coda)      # MCMC summaries
source("./utilities/plotting_theme.R")
# library(devtools) # For installing packages from GitHub
# install_github("atredennick/ecoforecastR") # get latest version
library(ecoforecastR) # MCMC manipulation (by M. Dietze)
####
####  LOAD FITTED MODELS -------------------------------------------------------
####
swe_est_posts <- readRDS("../results/swe_est_posteriors.RDS")
swe_avg_posts <- readRDS("../results/swe_est_posteriors.RDS")
####
#### PLOT POSTERIOR DISTRIBUTIONS ----------------------------------------------
####
## Redefine priors for plotting
r_mu_prior <- log(1.11) # lambda = 1.11 in Hobbs et al. 2015
r_sd_prior <- sd(log(rnorm(100000,1.11,0.024))) # sd_lambda = 0.024 in Hobbs et al. 2015
## Split output for swe_est model
out          <- list(params=NULL, predict=NULL)
mfit         <- as.matrix(swe_est_posts, chains=TRUE)
pred.cols    <- union(grep("z[",colnames(mfit),fixed=TRUE),grep("mu[",colnames(mfit),fixed=TRUE))
chain.col    <- which(colnames(mfit)=="CHAIN")
out$predict  <- mat2mcmc.list(mfit[,c(chain.col,pred.cols)])
out$params   <- mat2mcmc.list(mfit[,-pred.cols])
fitted_model <- out
post_params <- as.data.frame(as.matrix(fitted_model$params))
max_iters   <- nrow(post_params)
post_params <- post_params %>%
mutate(iteration = 1:max_iters) %>%
gather(key = parameter, value = estimate, -iteration) %>%
mutate(prior = c(rnorm(max_iters,0,1000), # b prior
rnorm(max_iters,0,1000), # b1 prior
rnorm(max_iters,r_mu_prior,r_sd_prior), # r prior
runif(max_iters,0,10))) # sd prior
docolor   <- "#278DAF"
prior_col <- "#CF4C26"
ggplot(post_params, aes(x = estimate, y = ..density..))+
geom_histogram(fill = docolor, color = "white", bins = 30)+
geom_line(data = filter(post_params, parameter == "r"),
aes(x = prior),
stat = "density",
color = "white",
size = 1.2)+
geom_line(data = filter(post_params, parameter == "r"),
aes(x = prior),
stat = "density",
color = prior_col)+
facet_wrap(~parameter, scales = "free", ncol = 4)+
ylab("Posterior density")+
xlab("Parameter estimate")+
my_theme_angle
ggsave(filename = "../figures/bison_post_params.png",
height = 3,
width = 10,
units = "in",
dpi = 120)
####
gelman.diag(swe_est_posts)
heidel.diag(swe_est_posts)
source('~/Repos/bison_forecast/code/fit_models.R')
names(mc3.out)
##  Split MCMC output for file constraints
saveRDS(mc3.out[[1]],"../results/swe_avg_posteriors_chain1.RDS")
saveRDS(mc3.out[[2]],"../results/swe_avg_posteriors_chain2.RDS")
saveRDS(mc3.out[[3]],"../results/swe_avg_posteriors_chain3.RDS")
################################################################################
##  bison_forecast.R: R script to fit a population growth model for YNP Bison,
##  forecast 7 new years.
##
##  ____________________________________________________________________________
##  Author:       Andrew Tredennick (atredenn@gmail.com)
##  Date created: December 1, 2017
################################################################################
##  Clear everything...
rm(list = ls(all.names = TRUE))
##  Set working directory to source file location
root <- "~/Repos/bison_forecast/"
setwd(paste0(root,"code/"))
####
####  LOAD LIBRARIES ----
####
library(tidyverse) # Data science functions
library(dplyr)     # Data wrangling
library(rjags)     # Fitting Bayesian models with JAGS
library(coda)      # MCMC summaries
# library(devtools) # For installing packages from GitHub
# install_github("atredennick/ecoforecastR") # get latest version
library(ecoforecastR) # MCMC manipulation (by M. Dietze)
####
####  LOAD DATA ----------------------------------------------------------------
####
snow_ynp  <- read.csv("../data/west_yellowstone_snotel_summary.csv", row.names = 1)
bison_raw <- read.csv("../data/YNP_bison_population_size.csv")
bison_dat <- bison_raw %>%
dplyr::select(-source) %>%     # drop the source column
mutate(set = ifelse(year < 2011, "training", "validation")) %>% # make new column for data splits
left_join(snow_ynp, by="year") # merge in SNOTEL data
####
####  JAGS State-Space Model ---------------------------------------------------
####
r_mu_prior <- log(1.11) # lambda = 1.11 in Hobbs et al. 2015
r_sd_prior <- sd(log(rnorm(100000,1.11,0.024))) # sd_lambda = 0.024 in Hobbs et al. 2015
my_model <- "
model{
#### Variance Priors
sigma_proc ~ dgamma(0.01,0.01)
tau_proc <- 1/sigma_proc^2
#### Fixed Effects Priors
r  ~ dnorm(0.1, 1/0.02^2) # intrinsic growth rate, informed prior
b  ~ dnorm(0,0.0001)      # strength of density dependence (r/K)
b1 ~ dnorm(0,0.0001)      # effect of snow
#### Initial Conditions
z[1] ~ dnorm(Nobs[1], tau_obs[1]) # varies around observed abundance at t = 1
#### Process Model
for(t in 2:npreds){
mu[t] <- max( 1, log( z[t-1]*exp(r + b*z[t-1] + b1*x[t]) ) )
z[t] ~ dlnorm(mu[t], tau_proc)
}
#### Data Model
for(j in 2:n){
Nobs[j] ~ dnorm(z[j], tau_obs[j])
}
}"
####
####  Fit Bison Forecasting Model ----------------------------------------------
####
##  For years without observation error, set to max observed standard deviation
##  TODO: Impute in the model?
na_sds                       <- which(is.na(bison_dat$count.sd)==T)
bison_dat[na_sds,"count.sd"] <- max(bison_dat$count.sd, na.rm=T)
##  Split into training and validation sets
training_dat   <- filter(bison_dat, set == "training")
validation_dat <- filter(bison_dat, set == "validation")
##  Set up SWE knowns (2011-2017), relative to scaling of observations
swe_mean     <- mean(training_dat$mean_snow_water_equiv_mm)
swe_sd       <- sd(training_dat$mean_snow_water_equiv_mm)
forecast_swe <- snow_ynp %>%
filter(year %in% validation_dat$year) %>%
pull(mean_snow_water_equiv_mm)
scl_fut_swe  <- (forecast_swe - swe_mean) / swe_sd
##  Set initial values for unkown parameters
inits <- list(
list(sigma_proc = 0.01,
r = 0.05,
b = -0.001,
b1 = -0.5),
list(sigma_proc = 0.3,
r = 0.4,
b = -0.1,
b1 = -0.01),
list(sigma_proc = 0.1,
r = 0.7,
b = -0.00001,
b1 = -0.2)
)
####
####  FIT AND FORECAST WITH KNOWN SWE
####
##  Prepare data list
mydat <- list(Nobs    = training_dat$count.mean, # mean counts
n       = nrow(training_dat), # number of observations
tau_obs = 1/training_dat$count.sd^2, # transform s.d. to precision
x       = c(as.numeric(scale(training_dat$mean_snow_water_equiv_mm)),scl_fut_swe), # snow depth, plus forecast years
npreds  = nrow(training_dat)+nrow(validation_dat)) # number of total predictions (obs + forecast)
##  Random variables to collect
out_variables <- c("r", "b", "b1", "sigma_proc", "z")
##  Send to JAGS
mc3     <- jags.model(file = textConnection(my_model),
data = mydat,
n.chains = length(inits),
n.adapt = 50000,
inits = inits)
update(mc3, n.iter = 100000)
mc3.out <- coda.samples(model=mc3,
variable.names=out_variables,
n.iter=100000)
##  Split MCMC output for file constraints
saveRDS(mc3.out[[1]],"../results/swe_est_posteriors_chain1.RDS")
saveRDS(mc3.out[[2]],"../results/swe_est_posteriors_chain2.RDS")
saveRDS(mc3.out[[3]],"../results/swe_est_posteriors_chain3.RDS")
################################################################################
##  analyze_posteriors.R: R script to plot the posterior distributions of model
##  parameters and to run MCMC diagnostics
##
##  ____________________________________________________________________________
##  Author:       Andrew Tredennick (atredenn@gmail.com)
##  Date created: October 19, 2016
################################################################################
##  Clear everything...
rm(list = ls(all.names = TRUE))
##  Set working directory to source file location
root <- "~/Repos/bison_forecast/"
setwd(paste0(root,"code/"))
####
####  LOAD LIBRARIES ----
####
library(tidyverse) # Data science functions
library(dplyr)     # Data wrangling
library(ggthemes)  # Pleasing themes for ggplot2
library(cowplot)   # Combining ggplots
library(rjags)     # Fitting Bayesian models with JAGS
library(coda)      # MCMC summaries
source("./utilities/plotting_theme.R")
# library(devtools) # For installing packages from GitHub
# install_github("atredennick/ecoforecastR") # get latest version
library(ecoforecastR) # MCMC manipulation (by M. Dietze)
####
####  LOAD FITTED MODELS -------------------------------------------------------
####
swe_est_posts <- as.mcmc.list <- list(readRDS("../results/swe_est_posteriors_chain1.RDS"),
readRDS("../results/swe_est_posteriors_chain2.RDS"),
readRDS("../results/swe_est_posteriors_chain3.RDS")
)
################################################################################
##  analyze_posteriors.R: R script to plot the posterior distributions of model
##  parameters and to run MCMC diagnostics
##
##  ____________________________________________________________________________
##  Author:       Andrew Tredennick (atredenn@gmail.com)
##  Date created: October 19, 2016
################################################################################
##  Clear everything...
rm(list = ls(all.names = TRUE))
##  Set working directory to source file location
root <- "~/Repos/bison_forecast/"
setwd(paste0(root,"code/"))
####
####  LOAD LIBRARIES ----
####
library(tidyverse) # Data science functions
library(dplyr)     # Data wrangling
library(ggthemes)  # Pleasing themes for ggplot2
library(cowplot)   # Combining ggplots
library(rjags)     # Fitting Bayesian models with JAGS
library(coda)      # MCMC summaries
source("./utilities/plotting_theme.R")
# library(devtools) # For installing packages from GitHub
# install_github("atredennick/ecoforecastR") # get latest version
library(ecoforecastR) # MCMC manipulation (by M. Dietze)
####
####  LOAD FITTED MODELS -------------------------------------------------------
####
swe_est_posts <- as.mcmc.list(list(readRDS("../results/swe_est_posteriors_chain1.RDS"),
readRDS("../results/swe_est_posteriors_chain2.RDS"),
readRDS("../results/swe_est_posteriors_chain3.RDS")))
source('~/Repos/bison_forecast/code/analyze_posteriors.R')
